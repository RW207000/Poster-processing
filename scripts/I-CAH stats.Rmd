---
title: "I-CAH stats"
author: "R.Welch"
date: "2025-03-05"
output: html_document
---

CODE TO BE USED ALONGSIDE 'CLEANED SCRIPT'

This code is used to provide stats on the data extracted from I-CAH.
- Three time frames are wanted: Nov22-23, Nov23-24, Nov24-Feb25

Want to create a minimal dataset.

For each time frame, and per centre, this code will provide the following:
- missing data (% and number of patients) for each element of the minimal dataset (outlined on CaHASE2 webpage: https://www.endocrinology.org/clinical-practice/research-projects/cahase-2/)
- How many patients have >1 entry (and create subset data frame to show these patients/records)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

libraries
```{r : reading libraries, include= FALSE}
packages <- c("tidyverse", "readxl", "dplyr", "magrittr", "mixtools", "emmeans", "readr","data.table", "lubridate", "ggplot2", "skimr", "ggstatsplot","summarytools", "knitr", "here", "ggthemes", "Amelia", "tidyr", "naniar", "stringr", "janitor")

lapply(packages, library, character.only = TRUE)
```

Reading in data.
```{r : reading in data}
participants <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/data/Core only 24.02.2025.csv", header=T, na.strings= c("", "NA"))
# participants$Date...CAH.Longitudinal.Data <- as.Date(participants$Date...CAH.Longitudinal.Data, format = "%d/%m/%Y")

medication <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/data/Glucocorticoids Data 24.02.2025.csv", header=T, na.strings= c("", "NA"))
medication <- remove_empty(medication, c("cols"), cutoff = 1)
# medication$assessment_date <- as.Date(medication$assessment_date, format = "%d/%m/%Y")

labs <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/data/Labs data 24.02.2025.csv", header=T, na.strings= c("", "NA"))
# labs$assessment_date <- as.Date(labs$assessment_date, format = "%d/%m/%Y")

longitudinal <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/data/Longitudinal data 24.02.2025.csv", header=T, na.strings= c("", "NA"))
```

Need to merge participants and longitudinal data frames
```{r : merging data frames}
participants_longitudinal <- merge(participants, longitudinal, by = "CO.ID",
              all = TRUE)

participants_longitudinal$Date.of.Assessment <- as.Date(participants_longitudinal$Date.of.Assessment, format = "%d/%m/%Y")

#make unique identifier
participants_longitudinal$CO.ID_assessment_date <- paste0(participants_longitudinal$CO.ID, participants_longitudinal$Date.of.Assessment)

write.csv(participants_longitudinal, file = "C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/data/participants_longitudinal.csv", row.names = F)
```

Before you start analysing data, remove any duplicated entries.
Duplicated entries occur when data has been entered twice. Usually with one or two fields differing between entries, indicating that one of the entries is incorrect and has subsequently been 'replaced' by a correct entry. You can't tell which entry is the correct one, so for safety we will remove all duplicated entries.

*********************************
*********************************
------Removing duplicates------

Making unique identifier for each assessment by combining co-id and assessment date.
```{r : making new unique identifier}
participants$coid_assedate <- paste(participants$CO.ID, participants$Date...CAH.Longitudinal.Data, sep = " ")
```

Checking for any duplicate entries (i.e.: any duplicates in the newly made unique identifier).
'list of duplicates frame' gives output of duplicate candidates
```{r : checking for duplicates}
duplicates <- freq(participants$coid_assedate)
duplicatesframe <- as.data.frame(duplicates)
duplicatesframe <- rownames_to_column(duplicatesframe, var="idvisitdate")
```

Now to remove any non-duplicates in 'duplicatesframe' to show us what the actual duplicates are and how many times they've been duplicated
```{r : isolating duplicate occurances, include= FALSE}
duplicatesframe <- duplicatesframe[duplicatesframe$idvisitdate != c("Total", "<NA>"),]
duplicatesframe <- duplicatesframe[-c(3:6)]

duplicateassessments <- duplicatesframe %>%
  filter(Freq>1)
```

Make a new vector to use as list of duplicate entries to remove from participants dataframe and then remove duplicated entries from participants dataframe with a subset.
Because there's no way of knowing which duplicate entry is the correct one, all duplicates are removed.
```{r : removing duplicates, include=FALSE}
idvisitstoremove <- duplicateassessments$idvisitdate

participantsnoduplicates <- subset(participants, !coid_assedate %in% idvisitstoremove)

freqcheck <- as.data.frame(freq(participantsnoduplicates$coid_assedate))
freqcheck <- rownames_to_column(freqcheck, var="idvisitdate")
freqcheck <- freqcheck[freqcheck$idvisitdate != c("Total", "<NA>"),]
# freqcheck
```

Making a dataframe of the removed duplicate assessment entries
```{r : removed duplicates}
toremove <- duplicateassessments$idvisitdate
removedrecords <- subset(participants, coid_assedate %in% toremove)

write.csv(removedrecords, file = "C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/outputs/removed_records", row.names = F)
```

Because I've removed all duplicate assessment entries, we might have lost participant/s if their only entry is one of these removed duplicates.
This will show which participants, if any, have been lost.
We need to split apart the idvisitdate to get the CO.IDs isolated
```{r : identifying lost participants}
duplicateassessments$id <- sapply(strsplit(duplicateassessments$idvisitdate," "), `[`, 1)
duplicateassessments$visitdate<- sapply(strsplit(duplicateassessments$idvisitdate," "), `[`, 2)

toremovelostparticipants <- participantsnoduplicates$CO.ID

lostparticipants <- NA
lostparticipants <- subset(participants, !CO.ID %in% toremovelostparticipants)

write.csv(lostparticipants, file = "C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/outputs/lostparticipants.csv", row.names = F)
```

```{r : making participantsnoduplicates, include=FALSE}
idvisitstoremove <- duplicateassessments$idvisitdate

participantsnoduplicates <- subset(participants, !coid_assedate %in% idvisitstoremove)

freqcheck <- as.data.frame(freq(participantsnoduplicates$coid_assedate))
freqcheck <- rownames_to_column(freqcheck, var="idvisitdate")
freqcheck <- freqcheck[freqcheck$idvisitdate != c("Total", "<NA>"),]
```


*********************************
*********************************
------Basic stats------

```{r : list of centres}
centres <-as.data.frame(unique(participants_longitudinal$Centre.ID.x))
centres <- centres %>%
  rename("Centre ID" = "unique(participants_longitudinal$Centre.ID.x)")

print("There are")
length(centres$`Centre ID`)
print("centres")
```

```{r : patients per centre}
patients_per_centre <- participants_longitudinal %>%
  group_by(Centre.ID.x) %>%
  summarise(n_unique(CO.ID)) %>%
  as.data.frame() %>%
   rename("number of patients" = "n_unique(CO.ID)")
```

```{r : visits per centre}
visits_per_centre <- participants_longitudinal %>%
  group_by(Centre.ID.x) %>%
  summarise(n = n()) %>%
  rename("number of visits" = "n")
```

```{r : combining patient and visit stats}
centre_stats <- full_join(patients_per_centre, visits_per_centre, by = "Centre.ID.x")

write.csv(centre_stats, file = "C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/outputs/centre_stats.csv", row.names = F)
```


*********************************
*********************************
------Minimal dataset subset------
Let's make a minimal data subset which we can use in subsequent analysis
Minimal data set includes:
Age, sex, medication, height, weight, BMI, blood pressure, biomarkers.
~ Also includes co-morbidities, fertility/pregnancy/menstrual info and genotype but these aren't provided in I-CAH tranches so cannot be investigated here.

We'll start by subsetting columns from participants_longitudinal. This contains: sex, height, weight, BMI, blood pressures (systolic and diastolic). Age can be calculated from DOB and assessment date
```{r : subsetting from participants_longitudinal}
minimal_data <- select(participants_longitudinal, c("CO.ID_assessment_date", "CO.ID", "Centre.ID.x", "Date.of.Birth.y", "Sex.at.birth.x", "Date.of.Assessment", "Weight..kg.", "Height..cm.", "BMI", "Systolic.Blood.Pressure", "Diastolic.Blood.Pressure"))

minimal_data <- minimal_data %>%
  rename("Centre ID" = "Centre.ID.x",
         "DOB" = "Date.of.Birth.y",
         "Sex" = "Sex.at.birth.x",
         "Date of assessment" = "Date.of.Assessment",
         "Weight.Kg" = "Weight..kg.",
         "Height.cm" = "Height..cm.")
```

Let's calculate age at assessment - this is an element of the minimal data set which is not provided/available in raw I-CAH data.
```{r : calculating age at assessment}
# start by making DOB and assessment date date formats
minimal_data$DOB <- as.Date(minimal_data$DOB, format = "%d/%m/%Y")
minimal_data$`Date of assessment` <- as.Date(minimal_data$`Date of assessment`, format = "%d/%m/%Y")

minimal_data$`Age at assessment (years)` <- interval(minimal_data$DOB, minimal_data$`Date of assessment`) / years(1)
minimal_data$`Age at assessment (years)` <- round(minimal_data$`Age at assessment (years)`, digits = 0)
```

At this point, we have: Age, sex, height, weight, BMI, blood pressure
Need to add in: medication and biomarkers.
Medication will come from 'meds_wide'.
Biomarkers will come from 'labs_wide'.
Let's just read in widened frames generated from 'cleaned script' processing code.

```{r : reading in meds_wide}
meds_wide <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/outputs/meds_wide.csv", header=T, na.strings= c("", "NA"))
# format date
meds_wide$Date.of.Assessment_1 <- as.Date(meds_wide$Date.of.Assessment_1, format = "%Y-%m-%d")

# let's add unique identifier
meds_wide$CO.ID_assessment_date <- paste0(meds_wide$CO.ID, meds_wide$Date.of.Assessment_1)

# identify and remove any duplicates
med_duplicates <- as.data.frame(freq(meds_wide$CO.ID_assessment_date))
med_duplicates <- rownames_to_column(med_duplicates, var="CO.ID_assessment_date")
med_duplicates <- med_duplicates[med_duplicates$CO.ID_assessment_date != c("Total", "<NA>"),]
med_duplicates <- med_duplicates[-c(3:6)]
med_duplicates <- med_duplicates %>%
  filter(Freq>1)

med_to_remove <- med_duplicates$CO.ID_assessment_date
meds_wide_no_duplicates <- subset(meds_wide, !CO.ID_assessment_date %in% med_to_remove)

# all frequencies here should be 1
med_freq_check <- as.data.frame(freq(meds_wide_no_duplicates$CO.ID_assessment_date))
```

```{r : reading in labs_wide}
labs_wide <- read.csv("C:/Users/md1rwe/Documents/Data extractions from I-CAH/Feb 2025/I-CAH_data_Feb_2025/outputs/labs_wide.csv", header=T, na.strings= c("", "NA"))
# format date
labs_wide$Date <- as.Date(labs_wide$Date, format = "%d/%m/%Y")

# let's add unique identifier
labs_wide$CO.ID_assessment_date <- paste0(labs_wide$CO.ID, labs_wide$Date)

# identify and remove any duplicates
lab_duplicates <- as.data.frame(freq(labs_wide$CO.ID_assessment_date))
lab_duplicates <- rownames_to_column(lab_duplicates, var="CO.ID_assessment_date")
lab_duplicates <- lab_duplicates[lab_duplicates$CO.ID_assessment_date != c("Total", "<NA>"),]
lab_duplicates <- lab_duplicates[-c(3:6)]
lab_duplicates <- lab_duplicates %>%
  filter(Freq>1)

lab_to_remove <- lab_duplicates$CO.ID_assessment_date
labs_wide_no_duplicates <- subset(labs_wide, !CO.ID_assessment_date %in% lab_to_remove)

# all frequencies here should be 1
lab_freq_check <- as.data.frame(freq(labs_wide_no_duplicates$CO.ID_assessment_date))
```


- to do next:
  left-join meds and labs to minimal data




